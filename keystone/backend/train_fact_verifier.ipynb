{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Train Fact Verifier (NLI Model)\n",
                "\n",
                "This notebook demonstrates how to fine-tune a Natural Language Inference (NLI) model for the `FactVerifier` component. \n",
                "The goal is to classify the relationship between a **Premise** (Evidence) and a **Hypothesis** (Claim) as:\n",
                "- `ENTAILMENT` (Supports)\n",
                "- `CONTRADICTION` (Refutes)\n",
                "- `NEUTRAL` (Not enough info)\n",
                "\n",
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install transformers datasets evaluate torch scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "\n",
                "# Add project root to path to import DatasetLoader\n",
                "sys.path.append(os.path.abspath('../../'))\n",
                "\n",
                "from keystone.data.dataset_loader import DatasetLoader\n",
                "import torch\n",
                "from datasets import Dataset, DatasetDict\n",
                "from transformers import (\n",
                "    AutoTokenizer,\n",
                "    AutoModelForSequenceClassification,\n",
                "    TrainingArguments,\n",
                "    Trainer,\n",
                "    DataCollatorWithPadding\n",
                ")\n",
                "import evaluate\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Dataset (FEVER)\n",
                "We use the `DatasetLoader` to fetch FEVER data. FEVER is a standard large-scale dataset for Fact Extraction and VERification."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "loader = DatasetLoader()\n",
                "# Load a small subset for demonstration. Increase max_samples for real training.\n",
                "raw_data = loader.load_fever(split=\"train\", max_samples=1000)\n",
                "\n",
                "print(f\"Loaded {len(raw_data)} examples.\")\n",
                "print(\"Sample:\", raw_data[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preprocess Data\n",
                "Convert the loader's format to HuggingFace Dataset format suitable for NLI training.\n",
                "Mapping:\n",
                "- `faithful` -> `ENTAILMENT` (Label 0)\n",
                "- `unverifiable` -> `NEUTRAL` (Label 1)\n",
                "- `hallucinated` -> `CONTRADICTION` (Label 2) (In our context)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "label2id = {\"faithful\": 0, \"unverifiable\": 1, \"hallucinated\": 2}\n",
                "id2label = {0: \"faithful\", 1: \"unverifiable\", 2: \"hallucinated\"}\n",
                "\n",
                "def prepare_nli_dataset(data):\n",
                "    hf_data = []\n",
                "    for item in data:\n",
                "        if item['label'] not in label2id: \n",
                "            continue\n",
                "            \n",
                "        # FEVER dataset 'source_document' might be empty in our loader if we didn't resolve Wiki pages.\n",
                "        # For this demo, we assume 'source_document' contains the evidence text.\n",
                "        # If the loader returned empty evidence, we skip or mock it.\n",
                "        premise = item.get('source_document') or \"Evidence text missing in demo loader\"\n",
                "        hypothesis = item.get('generated_text') # This is the claim\n",
                "        \n",
                "        hf_data.append({\n",
                "            \"text\": premise,\n",
                "            \"text_pair\": hypothesis,\n",
                "            \"label\": label2id[item['label']]\n",
                "        })\n",
                "    return hf_data\n",
                "\n",
                "formatted_data = prepare_nli_dataset(raw_data)\n",
                "dataset = Dataset.from_list(formatted_data)\n",
                "dataset = dataset.train_test_split(test_size=0.2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Tokenization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_name = \"cross-encoder/nli-deberta-v3-xsmall\" # Efficient base model\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "\n",
                "def preprocess_function(examples):\n",
                "    return tokenizer(\n",
                "        examples[\"text\"], \n",
                "        examples[\"text_pair\"], \n",
                "        truncation=True, \n",
                "        max_length=512\n",
                "    )\n",
                "\n",
                "tokenized_input = dataset.map(preprocess_function, batched=True)\n",
                "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = AutoModelForSequenceClassification.from_pretrained(\n",
                "    model_name, \n",
                "    num_labels=3, \n",
                "    id2label=id2label, \n",
                "    label2id=label2id,\n",
                "    ignore_mismatched_sizes=True # Only if resizing heads\n",
                ")\n",
                "\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=\"./nli_model_output\",\n",
                "    learning_rate=2e-5,\n",
                "    per_device_train_batch_size=8,\n",
                "    per_device_eval_batch_size=8,\n",
                "    num_train_epochs=3,\n",
                "    weight_decay=0.01,\n",
                "    evaluation_strategy=\"epoch\",\n",
                "    save_strategy=\"epoch\",\n",
                "    load_best_model_at_end=True,\n",
                ")\n",
                "\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_input[\"train\"],\n",
                "    eval_dataset=tokenized_input[\"test\"],\n",
                "    tokenizer=tokenizer,\n",
                "    data_collator=data_collator,\n",
                ")\n",
                "\n",
                "trainer.train()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "save_path = \"./saved_fact_verifier_model\"\n",
                "model.save_pretrained(save_path)\n",
                "tokenizer.save_pretrained(save_path)\n",
                "print(f\"Model saved to {save_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}